{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperating the Independent &  Dependent(Target) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Survived\"], axis=1 )#Independent variables\n",
    "y = data[\"Survived\"] #Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To create test Set, imort the train test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#By eqauting stratify=y, we can make the distribution same in train and test sets w.r.t \"y\" i.e the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution in Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"-\" *75)\n",
    "print(\"Distribution in Training Set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"-\" *75)\n",
    "print(\"Distribution in Testing Set:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "print(\"-\" *75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shape of Training Set and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import Decisiontree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "model = DecisionTreeClassifier(random_state=10)\n",
    "#Fitting the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking the training and testing score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Training Score:\", model.score(X_train,y_train))\n",
    "print(\"Testing Score:\", model.score(X_test,y_test))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen above, The Training accuracy is high as compared to the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the performance of DecisionTress: \n",
    "1. Optimising max_depth\n",
    "2. Optimising max_leaf nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Optimising max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "#Take the range of the max_depth 1-10 and checck its train_accuracy and test_accuracy\n",
    "for depth in range(1,10):\n",
    "    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=10)\n",
    "    dt_model.fit(X_train,y_train)\n",
    "    train_accuracy.append(dt_model.score(X_train,y_train))\n",
    "    test_accuracy.append(dt_model.score(X_test,y_test))    \n",
    "frame = pd.DataFrame({\"max_depth\": range(1,10), \"train_accuracy\" : train_accuracy, \"test_accuracy\": test_accuracy})\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the train_accuracy and test_accuracy w.r.t max_depth\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(frame['max_depth'], frame['test_accuracy'], marker='*')\n",
    "plt.plot(frame['max_depth'], frame['train_accuracy'], marker='*')\n",
    "plt.xlabel('Depth of tree')\n",
    "plt.ylabel('performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keeping the low value of max_depth, didnt allow the model to learn the pattern. Hence low prformance or Underfitting\n",
    "- Magnitude of increase in Training accuracy is higher as compared to that with the Testing accuracy-\n",
    "- **Max_depth= 8** produces the **highest Testing accuracy**,Hence can set the **max_depth = 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Optimising max_leaf nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Keeping the max_depth = 8, lets check the max_leaf node parameter to get highest teating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "#Keeping the max_depth = 8,take the range of the max_leaf_nodes(5,35,5) and check its train_accuracy and test_accuracy\n",
    "for leaf_nodes in range(5,35,5):\n",
    "    dt_model = DecisionTreeClassifier(max_leaf_nodes=leaf_nodes, max_depth=8, random_state=10)\n",
    "    dt_model.fit(X_train,y_train)\n",
    "    train_accuracy.append(dt_model.score(X_train,y_train))\n",
    "    test_accuracy.append(dt_model.score(X_test,y_test))    \n",
    "frame = pd.DataFrame({\"max_depth\": 8,\"max_leaf_nodes\": range(5,35,5), \"train_accuracy\" : train_accuracy, \"test_accuracy\": test_accuracy})\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Checking the Training Score and Testing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Training Score:\", dt_model.score(X_train,y_train))\n",
    "print(\"Testing Score:\", dt_model.score(X_test,y_test))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(frame['max_leaf_nodes'],frame['test_accuracy'], marker='*')\n",
    "plt.plot(frame['max_leaf_nodes'],frame['train_accuracy'], marker='*')\n",
    "plt.xlabel('Leaf_nodes of tree')\n",
    "plt.ylabel('performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it can thus be observed that the test_accuracy is maximum at 0.811659 when max_leaf_nodes= 20 and thereafter remains constant.\n",
    "- Hence we can take max_leaf_nodes as 20,25 0r 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearchCV, Optimise the hper parameters to get the to get highest teating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {#\"min_samples_split\":[int(x) for x in range(0,14,2)],\n",
    "       \"max_leaf_nodes\": [int(x) for x in np.linspace(5,35,7)],\n",
    "       \"max_depth\" :[8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_GridSearch = GridSearchCV(dt_model, param_grid= para, scoring= \"accuracy\", n_jobs= -1, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_GridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Training Score:\", dt_GridSearch.score(X_train,y_train))\n",
    "print(\"Testing Score:\", dt_GridSearch.score(X_test,y_test))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy scores are more in sync as compared to what we got previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt_GridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using GridSearchCV, we have got the max_leaf_nodes=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a Decision Tree using the best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plot_tree(dt_GridSearch.best_estimator_, feature_names= X.columns,class_names=['0','1'],filled=True, fontsize=11, rounded= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting Decision Trees in Textual Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.export_text(dt_GridSearch.best_estimator_,feature_names=list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
